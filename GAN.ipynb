{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LeakyReLU, BatchNormalization, Conv2D\n",
    "from keras.layers import Reshape, Flatten, Input, Activation, Conv2DTranspose\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from icecream import ic\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class DCGAN:\n",
    "    def __init__(self):\n",
    "        self.img_rows = 64\n",
    "        self.img_cols = 64\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        \n",
    "        self.gan = Sequential()\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        self.gan.add(self.generator)\n",
    "        self.gan.add(self.discriminator)\n",
    "        \n",
    "        optimizer = Adam(lr=0.00015, beta_1=0.5)\n",
    "        self.gan.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
    "                metrics=None)\n",
    "        \n",
    "    def build_generator(self):        \n",
    "        model = Sequential(name='generator')\n",
    "        \n",
    "        model.add(Dense(\n",
    "            units = 4 * 4 * 512,\n",
    "            kernel_initializer = 'glorot_uniform',\n",
    "            input_shape = (1, 1, 100))\n",
    "        )\n",
    "        model.add(Reshape(target_shape=(4, 4, 512)))\n",
    "        model.add(BatchNormalization(momentum=0.5))\n",
    "        model.add(Activation('relu'))\n",
    "        \n",
    "        model.add(Conv2DTranspose(\n",
    "            filters = 256, kernel_size = (5,5),\n",
    "            strides = (2, 2), padding = 'same',\n",
    "            data_format = 'channels_last',\n",
    "            kernel_initializer='glorot_uniform'\n",
    "        ))\n",
    "        model.add(BatchNormalization(momentum=0.5))\n",
    "        model.add(Activation('relu'))\n",
    "        \n",
    "        model.add(Conv2DTranspose(\n",
    "            filters = 128, kernel_size = (5,5),\n",
    "            strides = (2, 2), padding = 'same',\n",
    "            data_format = 'channels_last',\n",
    "            kernel_initializer='glorot_uniform'\n",
    "        ))\n",
    "        model.add(BatchNormalization(momentum=0.5))\n",
    "        model.add(Activation('relu'))\n",
    "        \n",
    "        model.add(Conv2DTranspose(\n",
    "            filters = 64, kernel_size = (5,5),\n",
    "            strides = (2, 2), padding = 'same',\n",
    "            data_format = 'channels_last',\n",
    "            kernel_initializer='glorot_uniform'\n",
    "        ))\n",
    "        model.add(BatchNormalization(momentum=0.5))\n",
    "        model.add(Activation('relu'))\n",
    "        \n",
    "        model.add(Conv2DTranspose(\n",
    "            filters = 3, kernel_size = (5,5),\n",
    "            strides = (2, 2), padding = 'same',\n",
    "            data_format = 'channels_last',\n",
    "            kernel_initializer='glorot_uniform'\n",
    "        ))\n",
    "        model.add(Activation('tanh'))\n",
    "        \n",
    "        optimizer = Adam(lr=0.00015, beta_1=0.5)\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=None)\n",
    "\n",
    "        model.summary()\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        \n",
    "        model = Sequential(name='discriminator')\n",
    "        \n",
    "        model.add(Conv2D(filters=64, kernel_size=(5, 5),\n",
    "                        strides = (2, 2), padding = 'same',\n",
    "                        data_format = 'channels_last',\n",
    "                        kernel_initializer = 'glorot_uniform',\n",
    "                        input_shape = img_shape))\n",
    "        model.add(BatchNormalization(momentum=0.5))\n",
    "        model.add(LeakyReLU(0.2))\n",
    "        \n",
    "        model.add(Conv2D(filters=128, kernel_size=(5, 5),\n",
    "                        strides = (2, 2), padding = 'same',\n",
    "                        data_format = 'channels_last',\n",
    "                        kernel_initializer = 'glorot_uniform'))\n",
    "        model.add(BatchNormalization(momentum=0.5))\n",
    "        model.add(LeakyReLU(0.2))\n",
    "        \n",
    "        model.add(Conv2D(filters=256, kernel_size=(5, 5),\n",
    "                        strides = (2, 2), padding = 'same',\n",
    "                        data_format = 'channels_last',\n",
    "                        kernel_initializer = 'glorot_uniform'))\n",
    "        model.add(BatchNormalization(momentum=0.5))\n",
    "        model.add(LeakyReLU(0.2))\n",
    "        \n",
    "        model.add(Conv2D(filters=512, kernel_size=(5, 5),\n",
    "                        strides = (2, 2), padding = 'same',\n",
    "                        data_format = 'channels_last',\n",
    "                        kernel_initializer = 'glorot_uniform'))\n",
    "        model.add(BatchNormalization(momentum=0.5))\n",
    "        model.add(LeakyReLU(0.2))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation('sigmoid'))\n",
    "        \n",
    "        optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                          optimizer=optimizer,\n",
    "                          metrics=None)\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    \n",
    "    def train(self, directory, epochs, batch_size):\n",
    "        images = []\n",
    "        \n",
    "        for img_name in os.listdir(directory):\n",
    "            if 'png' in img_name:\n",
    "                images.append(np.array(Image.open(os.path.join(directory, img_name))))\n",
    "        \n",
    "        images = np.array([img / 255.0 for img in images])\n",
    "    \n",
    "        ic(images.shape)\n",
    "\n",
    "        num_images = images.shape[0]\n",
    "        \n",
    "        number_of_batches = int(num_images / batch_size)\n",
    "        \n",
    "        adversarial_loss = np.empty(shape = 1)\n",
    "        discriminator_loss = np.empty(shape = 1)\n",
    "        batches = np.empty(shape = 1)\n",
    "        \n",
    "        plt.ion()\n",
    "        \n",
    "        current_batch = 0\n",
    "        \n",
    "        # with tqdm(range(epochs)) as pbar:\n",
    "        #     for epoch in range(epochs): \n",
    "        #         for batch_number in range(number_of_batches):\n",
    "        #             real_images = images[batch_number*batch_size:(batch_number + 1)*batch_size]\n",
    "                    \n",
    "        #             current_batch_size = real_images.shape[0]\n",
    "                    \n",
    "        #             noise = np.random.normal(0, 1, \n",
    "        #                                     size = (current_batch_size,) + (1, 1, 100))\n",
    "        #             generated_images = self.generator.predict(noise)\n",
    "                    \n",
    "        #             plt.imshow((generated_images[0] * 255).astype(np.uint8))\n",
    "                \n",
    "                \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 1, 1, 8192)        827392    \n",
      "                                                                 \n",
      " reshape_4 (Reshape)         (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 4, 4, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_24 (Activation)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_16 (Conv2D  (None, 8, 8, 256)        3277056   \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_25 (Activation)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_17 (Conv2D  (None, 16, 16, 128)      819328    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_26 (Activation)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_18 (Conv2D  (None, 32, 32, 64)       204864    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_27 (Activation)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_19 (Conv2D  (None, 64, 64, 3)        4803      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " activation_28 (Activation)  (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,137,283\n",
      "Trainable params: 5,135,363\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_16 (Conv2D)          (None, 32, 32, 64)        4864      \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 16, 16, 128)       204928    \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 8, 8, 256)         819456    \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 4, 4, 512)         3277312   \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 4, 4, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 8193      \n",
      "                                                                 \n",
      " activation_29 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,318,593\n",
      "Trainable params: 4,316,673\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramit/.local/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "gan = DCGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gan.train('./Shoe Images', epochs=10, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
